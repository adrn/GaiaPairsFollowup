{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "from astropy.constants import c\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('apw-notebook')\n",
    "%matplotlib inline\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from comoving_rv.log import logger\n",
    "from comoving_rv.db import Session, Base, db_connect\n",
    "from comoving_rv.db.model import (Run, Observation, TGASSource, SimbadInfo, PriorRV,\n",
    "                                  SpectralLineInfo, SpectralLineMeasurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Volumes/ProjectData/gaia-comoving-followup/'\n",
    "db_path = path.join(base_path, 'db.sqlite')\n",
    "engine = db_connect(db_path)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Halpha, = session.query(SpectralLineInfo.wavelength).filter(SpectralLineInfo.name == 'Halpha').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, only get observations that are done that have a Simbad RV already in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = session.query(Observation).join(Run, SpectralLineMeasurement, PriorRV)\n",
    "q = q.filter(Run.name == 'mdm-spring-2017')\n",
    "q = q.filter(SpectralLineMeasurement.x0 != None)\n",
    "q = q.filter(PriorRV.rv != None)\n",
    "q.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observations = q.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_offsets = np.zeros(len(observations)) * u.angstrom\n",
    "all_sky_offsets = np.full((len(observations), 3), np.nan) * u.angstrom\n",
    "true_rv = np.zeros(len(observations)) * u.km/u.s\n",
    "meas_rv = np.zeros(len(observations)) * u.km/u.s\n",
    "night_id = np.zeros(len(observations), dtype=int)\n",
    "obs_time = np.zeros(len(observations))\n",
    "airmass = np.zeros(len(observations))\n",
    "hour_angle = np.zeros(len(observations))\n",
    "color_by = np.zeros(len(observations))\n",
    "\n",
    "for i,obs in enumerate(observations):\n",
    "    print(obs.object, obs.filename_1d)\n",
    "    \n",
    "    # color_by[i] = obs.airmass\n",
    "    # color_by[i] = obs.exptime\n",
    "    \n",
    "    obs_time[i] = np.sum(np.array(list(map(float, obs.time_obs.split(':')))) / np.array([1., 60., 3600.]))\n",
    "    color_by[i] = obs_time[i]\n",
    "    night_id[i] = obs.night\n",
    "    airmass[i] = obs.airmass\n",
    "    hour_angle[i] = obs.ha.degree\n",
    "\n",
    "    x0 = obs.measurements[0].x0 * u.angstrom\n",
    "    offset = (x0 - Halpha)\n",
    "    raw_offsets[i] = offset\n",
    "    \n",
    "    sky_offsets = []\n",
    "    for j,meas in enumerate(obs.measurements[1:]):\n",
    "        sky_offset = meas.x0*u.angstrom - meas.info.wavelength\n",
    "        if meas.amp > 16 and meas.std_G < 2 and meas.std_G > 0.3 and np.abs(sky_offset) < 4*u.angstrom:\n",
    "            sky_offsets.append(sky_offset)\n",
    "            all_sky_offsets[i,j] = sky_offset\n",
    "            print(meas.info.name, meas.x0, meas.amp, sky_offset)\n",
    "            \n",
    "    sky_offsets = u.Quantity(sky_offsets)\n",
    "    \n",
    "    if len(sky_offsets) > 0:\n",
    "        sky_offset = np.mean(sky_offsets)\n",
    "    else:\n",
    "        sky_offset = 0. * u.angstrom\n",
    "        print(\"WARNING: not correcting with sky line\")\n",
    "    \n",
    "    # sky_offset = -1.2*u.angstrom\n",
    "    meas_rv[i] = (offset - sky_offset) / Halpha * c.to(u.km/u.s) + obs.v_bary\n",
    "    true_rv[i] = obs.prior_rv.rv - obs.v_bary\n",
    "    print(meas_rv[i] - true_rv[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_rv = raw_offsets / Halpha * c.to(u.km/u.s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is just total insanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(0, 14, 256)\n",
    "\n",
    "diff = all_sky_offsets[:,0] - ((raw_rv - true_rv)/c*5577*u.angstrom).decompose()\n",
    "# diff = all_sky_offsets[:,0] - ((meas_rv - true_rv)/c*5577*u.angstrom).decompose()\n",
    "diff[np.abs(diff) > 2*u.angstrom] = np.nan * u.angstrom\n",
    "\n",
    "night_polys = dict()\n",
    "for n in range(1,5+1):\n",
    "    mask = (night_id == n) & np.isfinite(diff)\n",
    "    coef = np.polyfit(obs_time[mask], diff[mask], deg=1, w=np.full(mask.sum(), 1/0.1))\n",
    "    poly = np.poly1d(coef)\n",
    "    night_polys[n] = poly\n",
    "    \n",
    "    plt.figure()\n",
    "    sc = plt.scatter(obs_time[mask], diff[mask])\n",
    "    plt.plot(grid, poly(grid), color=sc.get_facecolor()[0], marker='')\n",
    "    plt.title('n{}'.format(n))\n",
    "    plt.xlim(-0, 15)\n",
    "    plt.ylim(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_rv = np.zeros(len(observations)) * u.km/u.s\n",
    "\n",
    "# derps = {1: -0*u.km/u.s/c * 6563.*u.angstrom, \n",
    "#          2: -22*u.km/u.s/c * 6563.*u.angstrom, \n",
    "#          4: -13*u.km/u.s/c * 6563.*u.angstrom}\n",
    "derps = {}\n",
    "for n in np.unique(night_id):\n",
    "    mask = night_id == n\n",
    "    \n",
    "    sky_offset = np.nanmean(all_sky_offsets[mask,:2], axis=1)\n",
    "    sky_offset[np.isnan(sky_offset)] = 0.*u.angstrom\n",
    "    sky_offset -= night_polys[n](obs_time[mask]) * u.angstrom\n",
    "    \n",
    "    if n in derps:\n",
    "        derp = derps[n]\n",
    "    else:\n",
    "        derp = 0*u.angstrom\n",
    "    \n",
    "    corrected_rv[mask] = (raw_offsets[mask] - sky_offset - derp) / Halpha * c.to(u.km/u.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2, 5, figsize=(15,6.5), sharex='row', sharey='row')\n",
    "\n",
    "_lim = (-200, 200)\n",
    "_grid = np.linspace(_lim[0], _lim[1], 16)\n",
    "_bins = np.linspace(-100, 100, 31)\n",
    "for n in range(1,5+1):\n",
    "    ax = axes[0, n-1]\n",
    "    \n",
    "    mask = night_id == n\n",
    "    cb = ax.scatter(corrected_rv[mask], true_rv[mask], c=color_by[mask], \n",
    "                   marker='.', alpha=0.75, vmin=0, vmax=12, linewidth=1., \n",
    "                    edgecolor='#aaaaaa', s=50)\n",
    "    ax.plot(_grid, _grid, marker='', zorder=-10, color='#888888')\n",
    "    \n",
    "    # histogram\n",
    "    ax = axes[1, n-1]\n",
    "    drv = corrected_rv[mask] - true_rv[mask]\n",
    "    ax.hist(drv, bins=_bins)\n",
    "    \n",
    "    print(n, np.median(drv), 1.5 * np.median(np.abs(drv - np.median(drv))), np.mean(drv), np.std(drv))\n",
    "    \n",
    "axes[0,0].set_xlim(_lim)\n",
    "axes[0,0].set_ylim(_lim)\n",
    "axes[1,0].set_xlim(_bins.min(), _bins.max())\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# all:\n",
    "drv = corrected_rv - true_rv\n",
    "print('total:', 1.5 * np.median(np.abs(drv - np.median(drv))), np.std(drv[np.abs(drv) < 50*u.km/u.s]))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(drv[np.abs(drv) < 100*u.km/u.s], bins='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do same as above, as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RVCorrector(object):\n",
    "\n",
    "    def __init__(self, session, run_name):\n",
    "        self.session = session\n",
    "        self.run_name = str(run_name)\n",
    "\n",
    "        # get wavelength for Halpha\n",
    "        self.Halpha, = session.query(SpectralLineInfo.wavelength)\\\n",
    "                              .filter(SpectralLineInfo.name == 'Halpha').one()\n",
    "\n",
    "        self._compute_offset_corrections()\n",
    "\n",
    "    def _compute_offset_corrections(self):\n",
    "        session = self.session\n",
    "        run_name = self.run_name\n",
    "\n",
    "        q = session.query(Observation).join(Run, SpectralLineMeasurement, PriorRV)\n",
    "        q = q.filter(Run.name == run_name)\n",
    "        q = q.filter(SpectralLineMeasurement.x0 != None)\n",
    "        q = q.filter(PriorRV.rv != None)\n",
    "        logger.debug('{0} observations with prior RV measurements'\n",
    "                     .format(q.distinct().count()))\n",
    "\n",
    "        # retrieve all observations with measured centroids and previous RV's\n",
    "        observations = q.all()\n",
    "\n",
    "        # What we do below is look at the residual offsets between applying a na\u00efve\n",
    "        # sky-line correction and the true RV (with the barycentric velocity\n",
    "        # applied)\n",
    "\n",
    "        raw_offsets = np.zeros(len(observations)) * u.angstrom\n",
    "        all_sky_offsets = np.full((len(observations), 3), np.nan) * u.angstrom\n",
    "        true_rv = np.zeros(len(observations)) * u.km/u.s\n",
    "        obs_time = np.zeros(len(observations))\n",
    "        night_id = np.zeros(len(observations), dtype=int)\n",
    "        corrected_rv = np.zeros(len(observations)) * u.km/u.s\n",
    "\n",
    "        for i,obs in enumerate(observations):\n",
    "            # convert obstime into decimal hour\n",
    "            obs_time[i] = np.sum(np.array(list(map(float, obs.time_obs.split(':')))) / np.array([1., 60., 3600.]))\n",
    "\n",
    "            # Compute the raw offset: difference between Halpha centroid and true\n",
    "            # wavelength value\n",
    "            x0 = obs.measurements[0].x0 * u.angstrom\n",
    "            offset = (x0 - self.Halpha)\n",
    "            raw_offsets[i] = offset\n",
    "\n",
    "            night_id[i] = obs.night\n",
    "\n",
    "            # For each sky line (that passes certain quality checks), compute the\n",
    "            # offset between the predicted wavelength and measured centroid\n",
    "            # TODO: generalize these quality cuts - see also below in\n",
    "            # get_corrected_rv\n",
    "            sky_offsets = []\n",
    "            for j,meas in enumerate(obs.measurements[1:]):\n",
    "                sky_offset = meas.x0*u.angstrom - meas.info.wavelength\n",
    "                if (meas.amp > 16 and meas.std_G < 2 and meas.std_G > 0.3 and\n",
    "                        np.abs(sky_offset) < 4*u.angstrom): # MAGIC NUMBER: quality cuts\n",
    "                    sky_offsets.append(sky_offset)\n",
    "                    all_sky_offsets[i,j] = sky_offset\n",
    "\n",
    "            sky_offsets = u.Quantity(sky_offsets)\n",
    "\n",
    "            if len(sky_offsets) > 0:\n",
    "                sky_offset = np.mean(sky_offsets)\n",
    "            else:\n",
    "                sky_offset = np.nan * u.angstrom\n",
    "                logger.debug(\"not correcting with sky line for {0}\".format(obs))\n",
    "\n",
    "            true_rv[i] = obs.prior_rv.rv - obs.v_bary\n",
    "\n",
    "        raw_rv = raw_offsets / self.Halpha * c.to(u.km/u.s)\n",
    "\n",
    "        # unique night ID's\n",
    "        unq_night_id = np.unique(night_id)\n",
    "        unq_night_id.sort()\n",
    "\n",
    "        # Now we do a totally insane thing. From visualizing the residual\n",
    "        # differences, there seems to be a trend with the observation time. We\n",
    "        # fit a line to these residuals and use this to further correct the\n",
    "        # wavelength solutions using just the (strongest) [OI] 5577 \u00c5 line.\n",
    "        diff = all_sky_offsets[:,0] - ((raw_rv - true_rv)/c*5577*u.angstrom).decompose()\n",
    "        diff[np.abs(diff) > 2*u.angstrom] = np.nan * u.angstrom # reject BIG offsets\n",
    "\n",
    "        self._night_polys = dict()\n",
    "        self._night_final_offsets = dict()\n",
    "        for n in unq_night_id:\n",
    "            mask = (night_id == n) & np.isfinite(diff)\n",
    "            coef = np.polyfit(obs_time[mask], diff[mask], deg=1, w=np.full(mask.sum(), 1/0.1))\n",
    "            poly = np.poly1d(coef)\n",
    "            self._night_polys[n] = poly\n",
    "\n",
    "            sky_offset = np.nanmean(all_sky_offsets[mask,:2], axis=1)\n",
    "            sky_offset[np.isnan(sky_offset)] = 0.*u.angstrom\n",
    "            sky_offset -= self._night_polys[n](obs_time[mask]) * u.angstrom\n",
    "\n",
    "            corrected_rv[mask] = (raw_offsets[mask] - sky_offset) / self.Halpha * c.to(u.km/u.s)\n",
    "\n",
    "            # Finally, we align the median of each night's \u2206RV distribution with 0\n",
    "            drv = corrected_rv[mask] - true_rv[mask]\n",
    "            self._night_final_offsets[n] = np.nanmedian(drv)\n",
    "\n",
    "        # now estimate the std. dev. uncertainty using the MAD\n",
    "        all_drv = corrected_rv - true_rv\n",
    "        self._abs_err = 1.5 * np.nanmedian(np.abs(all_drv - np.nanmedian(all_drv)))\n",
    "\n",
    "    def get_corrected_rv(self, obs):\n",
    "        \"\"\"Compute a corrected radial velocity for the given observation\"\"\"\n",
    "\n",
    "        # Compute the raw offset: difference between Halpha centroid and true\n",
    "        # wavelength value\n",
    "        x0 = obs.measurements[0].x0 * u.angstrom\n",
    "        raw_offset = (x0 - self.Halpha)\n",
    "\n",
    "        # precision estimate from line centroid error\n",
    "        precision = (obs.measurements[0].x0_error* u.angstrom) / self.Halpha * c.to(u.km/u.s)\n",
    "\n",
    "        # For each sky line (that passes certain quality checks), compute the\n",
    "        # offset between the predicted wavelength and measured centroid\n",
    "        # TODO: generalize these quality cuts - see also above in\n",
    "        # _compute_offset_corrections\n",
    "        sky_offsets = np.full(3, np.nan) * u.angstrom\n",
    "        for j,meas in enumerate(obs.measurements[1:]):\n",
    "            sky_offset = meas.x0*u.angstrom - meas.info.wavelength\n",
    "            if (meas.amp > 16 and meas.std_G < 2 and meas.std_G > 0.3 and\n",
    "                    np.abs(sky_offset) < 3.3*u.angstrom): # MAGIC NUMBER: quality cuts\n",
    "                sky_offsets[j] = sky_offset\n",
    "\n",
    "        # final sky offset to apply\n",
    "        flag = 0\n",
    "        sky_offset = np.nanmean(sky_offsets)\n",
    "        if np.isnan(sky_offset.value):\n",
    "            logger.debug(\"not correcting with sky line for {0}\".format(obs))\n",
    "            sky_offset = 0*u.angstrom\n",
    "            flag = 1\n",
    "\n",
    "        # apply global sky offset correction - see _compute_offset_corrections()\n",
    "        sky_offset -= self._night_polys[obs.night](obs.utc_hour) * u.angstrom\n",
    "\n",
    "        # compute radial velocity and correct for sky line\n",
    "        rv = (raw_offset - sky_offset) / self.Halpha * c.to(u.km/u.s)\n",
    "\n",
    "        # correct for offset of median of \u2206RV distribution from targets with\n",
    "        # prior/known RV's\n",
    "        rv -= self._night_final_offsets[obs.night]\n",
    "\n",
    "        # rv error\n",
    "        err = np.sqrt(self._abs_err**2 + precision**2)\n",
    "\n",
    "        return rv, err, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_corr = RVCorrector(session, 'mdm-spring-2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_rv2 = np.zeros_like(corrected_rv)\n",
    "err = np.zeros_like(corrected_rv)\n",
    "flags = np.zeros(len(corrected_rv2))\n",
    "for i,obs in enumerate(observations):\n",
    "    corrected_rv2[i], err[i], flags[i] = rv_corr.get_corrected_rv(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2, 5, figsize=(15,6.5), sharex='row', sharey='row')\n",
    "\n",
    "_lim = (-200, 200)\n",
    "_grid = np.linspace(_lim[0], _lim[1], 16)\n",
    "_bins = np.linspace(-100, 100, 31)\n",
    "for n in range(1,5+1):\n",
    "    ax = axes[0, n-1]\n",
    "    \n",
    "    mask = (night_id == n) & (flags == 0)\n",
    "    cb = ax.scatter(corrected_rv2[mask], true_rv[mask], c=color_by[mask], \n",
    "                   marker='.', alpha=0.75, vmin=0, vmax=12, linewidth=1., \n",
    "                    edgecolor='#aaaaaa', s=50)\n",
    "    ax.plot(_grid, _grid, marker='', zorder=-10, color='#888888')\n",
    "    \n",
    "    # histogram\n",
    "    ax = axes[1, n-1]\n",
    "    drv = corrected_rv2[mask] - true_rv[mask]\n",
    "    ax.hist(drv, bins=_bins)\n",
    "    \n",
    "    print(n, np.median(drv), 1.5 * np.median(np.abs(drv - np.median(drv))), np.mean(drv), np.std(drv))\n",
    "    \n",
    "axes[0,0].set_xlim(_lim)\n",
    "axes[0,0].set_ylim(_lim)\n",
    "axes[1,0].set_xlim(_bins.min(), _bins.max())\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# all:\n",
    "drv = corrected_rv2 - true_rv\n",
    "print('total:', 1.5 * np.median(np.abs(drv - np.median(drv))), np.std(drv[np.abs(drv) < 50*u.km/u.s]))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(drv[np.abs(drv) < 100*u.km/u.s], bins='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(3, 5, figsize=(15,8), sharex=True, sharey=True)\n",
    "\n",
    "for n in range(1,5+1):\n",
    "    ax = axes[:,n-1]\n",
    "    mask = night_id == n\n",
    "    \n",
    "    for j in range(3):\n",
    "        ax[j].scatter(obs_time[mask], all_sky_offsets[mask,j], c=np.arange(mask.sum()), cmap='jet')\n",
    "    \n",
    "    ax[0].set_title('night {0}'.format(n))\n",
    "\n",
    "axes[2,2].set_xlabel('time [hour]')\n",
    "axes[0,0].set_ylabel('5577 offset')\n",
    "axes[1,0].set_ylabel('6300 offset')\n",
    "axes[2,0].set_ylabel('6364 offset')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# ---\n",
    "\n",
    "fig,axes = plt.subplots(3, 5, figsize=(15,8), sharex=True, sharey=True)\n",
    "\n",
    "for n in range(1,5+1):\n",
    "    ax = axes[:,n-1]\n",
    "    mask = night_id == n\n",
    "    \n",
    "    for j in range(3):\n",
    "#         ax[j].scatter(hour_angle[mask], all_sky_offsets[mask,j], c=np.arange(mask.sum()), cmap='jet')\n",
    "        ax[j].scatter(hour_angle[mask], all_sky_offsets[mask,j], c=airmass[mask], \n",
    "                      cmap='Spectral', edgecolor='#555555', linewidth=1)\n",
    "    \n",
    "    ax[0].set_title('night {0}'.format(n))\n",
    "\n",
    "axes[2,2].set_xlabel('time [hour]')\n",
    "axes[0,0].set_ylabel('5577 offset')\n",
    "axes[1,0].set_ylabel('6300 offset')\n",
    "axes[2,0].set_ylabel('6364 offset')\n",
    "\n",
    "axes[0,0].set_xlim(-75, 75)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((raw_rv - true_rv)[mask]/c*5577).decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "for n in range(1,5+1):\n",
    "    mask = night_id == n\n",
    "    plt.scatter(all_sky_offsets[mask,0], \n",
    "                ((raw_rv - true_rv)[mask]/c*5577).decompose())\n",
    "plt.xlim(-2.5,2.5)\n",
    "# plt.ylim(-150,150)\n",
    "plt.ylim(-2.5,2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Take a peek at velocity differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = session.query(Observation.group_id).join(Run, SpectralLineMeasurement)\n",
    "q = q.filter(Run.name == 'mdm-spring-2017')\n",
    "print(q.distinct().count())\n",
    "gids = np.array([gid for gid, in q.distinct().all()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rv_diffs = []\n",
    "all_x0s = []\n",
    "for gid in gids:\n",
    "    meas_q = session.query(SpectralLineMeasurement).join(Observation, SpectralLineInfo)\n",
    "    meas_q = meas_q.filter(SpectralLineInfo.name == 'Halpha')\n",
    "    meas_q = meas_q.filter(Observation.group_id == gid)\n",
    "    x0s = [meas.x0 for meas in meas_q.all()]\n",
    "    \n",
    "    if len(x0s) == 2:\n",
    "        rv_diff = (x0s[1] - x0s[0])*u.angstrom / Halpha * c.to(u.km/u.s)\n",
    "        rv_diffs.append(rv_diff)\n",
    "        \n",
    "        all_x0s = all_x0s + x0s\n",
    "    \n",
    "    else:\n",
    "        rv_diffs.append(np.nan*u.km/u.s)\n",
    "        \n",
    "rv_diffs = u.Quantity(rv_diffs)\n",
    "all_x0s = u.Quantity(all_x0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random shuffle\n",
    "# TODO: redo this after correcting for barycenter, sky shifts, etc.\n",
    "_derp = np.random.choice(len(all_x0s), size=len(all_x0s), replace=False)\n",
    "random_rv_diff = (all_x0s - all_x0s[_derp])*u.angstrom / Halpha * c.to(u.km/u.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,bins,_ = plt.hist(rv_diffs[np.isfinite(rv_diffs)], bins=np.linspace(-150, 150, 31), \n",
    "                    normed=True, alpha=0.5)\n",
    "\n",
    "plt.hist(np.random.normal(0, np.sqrt(25**2 + 25**2 + 5**2 + 5**2), size=64000), \n",
    "         bins=bins, normed=True, alpha=0.5);\n",
    "\n",
    "_,bins,_ = plt.hist(random_rv_diff[np.isfinite(random_rv_diff)], bins=bins, normed=True, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at differences in sky lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sky_diffs = []\n",
    "for gid in gids:\n",
    "    meas_q = session.query(SpectralLineMeasurement).join(Observation, SpectralLineInfo)\n",
    "    meas_q = meas_q.filter(SpectralLineInfo.name == '[OI] 6300')\n",
    "    meas_q = meas_q.filter(Observation.group_id == gid)\n",
    "    x0s = [meas.x0 for meas in meas_q.all()]\n",
    "\n",
    "    if len(x0s) == 2:\n",
    "        sky_diff = (x0s[1] - x0s[0])*u.angstrom / (6300*u.angstrom) * c.to(u.km/u.s)\n",
    "        sky_diffs.append(sky_diff)\n",
    "    \n",
    "    else:\n",
    "        sky_diffs.append(np.nan*u.km/u.s)\n",
    "    \n",
    "sky_diffs = u.Quantity(sky_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sky_diffs[np.isfinite(sky_diffs)], bins=np.linspace(-50, 50, 30));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ok, so apparently I need to correct for sky line shifts before doing RV difference??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seps = []\n",
    "for gid in gids[np.isfinite(rv_diffs) & (rv_diffs < 15*u.km/u.s)]:\n",
    "    _q = session.query(TGASSource).join(Observation)\n",
    "    _q = _q.filter(Observation.group_id == gid)\n",
    "    tgas_data = _q.all()\n",
    "    \n",
    "    c1 = tgas_data[0].skycoord\n",
    "    c2 = tgas_data[1].skycoord\n",
    "    \n",
    "    sep = c1.separation_3d(c2)\n",
    "    seps.append(sep)\n",
    "\n",
    "seps = u.Quantity(seps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(seps[seps > 0*u.pc], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:comoving-rv]",
   "language": "python",
   "name": "conda-env-comoving-rv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}