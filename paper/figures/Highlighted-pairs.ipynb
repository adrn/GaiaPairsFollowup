{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You have to run `paper/figures/fit_isochrones.py` before producing the plots here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.constants import c\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('apw-notebook')\n",
    "%matplotlib inline\n",
    "from scipy.stats import scoreatpercentile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from comoving_rv.db import Session, Base, db_connect\n",
    "from comoving_rv.db.model import (Run, Observation, TGASSource, SimbadInfo, GroupToObservations,\n",
    "                                  SpectralLineInfo, SpectralLineMeasurement, RVMeasurement, Photometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_path = '/Volumes/ProjectData/gaia-comoving-followup/'\n",
    "base_path = '../../data/'\n",
    "db_path = path.join(base_path, 'db.sqlite')\n",
    "engine = db_connect(db_path)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [this notebook, end](Color-magnitude diagram.ipynb) for the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interesting_group_ids = [1500, 1229,  1515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbls = OrderedDict()\n",
    "for gid in interesting_group_ids:\n",
    "    for f in os.listdir('isochrone_chains/'):\n",
    "        if f.startswith(str(gid)):\n",
    "            if gid not in tbls:\n",
    "                tbls[gid] = OrderedDict()\n",
    "        \n",
    "            tbl = pd.read_hdf('isochrone_chains/{0}'.format(f), \n",
    "                              key='samples')\n",
    "            tbls[gid][f.split('.')[0]] = tbl[::64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbls.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's just compile the separation info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAD(x):\n",
    "    return np.median(np.abs(x - np.median(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gid in tbls:\n",
    "    obs1, obs2 = session.query(Observation).filter(Observation.group_id == gid).all()\n",
    "    \n",
    "    print(obs1.simbad_info.preferred_name, obs2.simbad_info.preferred_name)\n",
    "    print('TGAS ids: {0} {1}'.format(obs1.tgas_source.source_id,\n",
    "                                     obs2.tgas_source.source_id))\n",
    "    \n",
    "    raw_rv_diff = (obs1.measurements[0].x0 - obs2.measurements[0].x0) / 6563. * c.to(u.km/u.s)    \n",
    "    mean_rv = np.mean([obs1.rv_measurement.rv.value, \n",
    "                       obs2.rv_measurement.rv.value]) * obs2.rv_measurement.rv.unit\n",
    "    \n",
    "    rv1 = mean_rv + raw_rv_diff/2.\n",
    "    rv_err1 = obs1.measurements[0].x0_error / 6563. * c.to(u.km/u.s)\n",
    "    rv2 = mean_rv - raw_rv_diff/2.\n",
    "    rv_err2 = obs2.measurements[0].x0_error / 6563. * c.to(u.km/u.s)\n",
    "    \n",
    "    # Compute point-estimate difference in 3D velocity\n",
    "    icrs1 = obs1.icrs_samples(size=2**15, custom_rv=(rv1, rv_err1))\n",
    "    icrs2 = obs2.icrs_samples(size=2**15, custom_rv=(rv2, rv_err2))\n",
    "    \n",
    "    sep2d = icrs1.separation(icrs2)\n",
    "    sep3d = icrs1.separation_3d(icrs2)\n",
    "    R = np.mean([icrs1.distance.value, icrs2.distance.value], axis=0) * u.pc\n",
    "    chord = 2*R*np.sin(sep2d/2)\n",
    "    \n",
    "    print(\"Angular sep.: {:.2f}\".format(sep2d[0]))\n",
    "    print(\"Chord length: {:.2f} +/- {:.2f}\".format(np.median(chord), 1.5*MAD(chord)))\n",
    "    print(\"3D sep.: {:.2f} +/- {:.2f}\".format(np.median(sep3d), 1.5*MAD(sep3d)))\n",
    "    print(\"parallaxes: {:.2f} +/- {:.2f}, {:.2f} +/- {:.2f}\"\n",
    "          .format(obs1.tgas_source.parallax, obs1.tgas_source.parallax_error,\n",
    "                  obs2.tgas_source.parallax, obs2.tgas_source.parallax_error))\n",
    "    \n",
    "    rep1 = icrs1.represent_as('cartesian')\n",
    "    rep2 = icrs2.represent_as('cartesian')\n",
    "    \n",
    "    dv = (rep1.differentials['s'] - rep2.differentials['s']).norm().to(u.km/u.s)\n",
    "    print('|\u2206v| = {:.2f} + {:.2f} - {:.2f}'.format(np.median(dv), \n",
    "                                                   np.median(dv.value)-scoreatpercentile(dv.value, 15),\n",
    "                                                   scoreatpercentile(dv.value, 85)-np.median(dv.value)))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = 1000 / np.random.normal(15.68, 0.32, size=100000) \n",
    "d1 = 1000 / np.random.normal(17.98, 0.44, size=100000) \n",
    "# plt.hist(d1, bins='auto')\n",
    "# plt.hist(d2, bins='auto', alpha=0.5);\n",
    "plt.hist(np.abs(d1 - d2), bins='auto');\n",
    "print(np.median(d1), np.std(d1))\n",
    "print(np.median(d2), np.std(d2))\n",
    "print(np.sqrt(np.median(np.abs(d1 - d2))**2 + 3.3**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we look at stellar parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for gid in tbls:\n",
    "    obses = []\n",
    "    for name in tbls[gid]: \n",
    "        obses.append(session.query(Observation).filter(Observation.object == name).one())\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8,8))\n",
    "    \n",
    "    axes[0,0].set_ylabel('$V$ [mag]')\n",
    "    axes[1,0].set_ylabel('log$g$')\n",
    "    \n",
    "    for i,name in enumerate(tbls[gid]):\n",
    "        tbl = tbls[gid][name]\n",
    "        common_name = obses[i].simbad_info.preferred_name\n",
    "        \n",
    "        axes[0,i].plot(tbl['B_mag'], tbl['V_mag'], marker='.', linestyle='none', alpha=0.5)\n",
    "        axes[0,i].set_title(common_name)\n",
    "        axes[0,i].set_xlabel('$B$ [mag]')\n",
    "        \n",
    "        axes[1,i].plot(tbl['Teff_0_0'], tbl['logg_0_0'], marker='.', linestyle='none', alpha=0.5)\n",
    "        axes[1,i].set_xlabel(r'$T_{\\rm eff}$ [K]')\n",
    "        \n",
    "        print(\"{0}\\n-----------------\".format(common_name))\n",
    "        for par in ['logg', 'Teff', 'mass', 'radius']:\n",
    "            med = np.median(tbl[par+'_0_0'])\n",
    "            mad = np.median(np.abs(tbl[par+'_0_0'] - med))\n",
    "            print('{0} = {1:.2f} +/- {2:.3f}'.format(par, med, 1.5 * mad))\n",
    "        print(\"-----------------\\n\\n\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:comoving-rv]",
   "language": "python",
   "name": "conda-env-comoving-rv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}